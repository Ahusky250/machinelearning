{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'D:\\Project\\jupyter\\machinelearning\\horse_colic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('watermelon3_0alpha.csv')\n",
    "#df['outcome']\n",
    "dataMat = np.mat(df[['density', 'suger_ratio']].values)\n",
    "labelMat = np.mat(df[['clas']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSimpData():\n",
    "    datMat = np.matrix([[ 1. ,  2.1],\n",
    "        [ 2. ,  1.1],\n",
    "        [ 1.3,  1. ],\n",
    "        [ 1. ,  1. ],\n",
    "        [ 2. ,  1. ]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return datMat,classLabels\n",
    "dataMat, labelMat = loadSimpData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):#just classify the data\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0],1))\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input:\n",
    "    D: 权重向量\n",
    "\n",
    "\"\"\"\n",
    "def buildStump(dataMatrix,labelMat,D):\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    numSteps = 10.0; bestStump = {}; bestClasEst = np.mat(np.zeros((m,1)))\n",
    "    minError = np.inf #init error sum, to +infinity\n",
    "    for i in range(n):#loop over all dimensions\n",
    "        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps\n",
    "        for j in range(-1,int(numSteps)+1):#loop over all range in current dimension\n",
    "            for inequal in ['lt', 'gt']: #go over less than and greater than\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)#call stump classify with i, j, lessThan\n",
    "                errArr = np.mat(np.ones((m,1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T*errArr  #calc total error multiplied by D\n",
    "                #print(\"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError))\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump,minError,bestClasEst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "基于\"重赋权法\"的特定数据分布\n",
    "input:\n",
    "    dataMat:数据集\n",
    "    T:训练轮数\n",
    "output:\n",
    "    H(x) = sign(求和alphat * ht(x))\n",
    "\"\"\"\n",
    "def adaBoostTrain(dataMat, labelMat, T):\n",
    "    weakClassfier = []\n",
    "    row, col = dataMat.shape\n",
    "    D = np.mat(np.ones((row, 1)) / row)\n",
    "    aggClassEst = np.mat(np.zeros((row, 1)))\n",
    "    for i in range(T):\n",
    "        bestStump, error, classEst = buildStump(dataMat, labelMat, D)\n",
    "        if error > 0.5 :\n",
    "            break\n",
    "        alpha = float(0.5 * np.log((1 - error)/error))\n",
    "        bestStump['alpha'] = alpha\n",
    "        D = np.multiply(D, np.exp(-alpha * np.multiply(labelMat, classEst)))/D.sum()\n",
    "        weakClassfier.append(bestStump)\n",
    "        aggClassEst += alpha * classEst\n",
    "        print('第{}个分类器 aggClassEst : {}'.format(i, aggClassEst))\n",
    "        aggError = np.multiply((np.sign(aggClassEst) != labelMat), labelMat)\n",
    "        errorRate = aggError.sum() / row\n",
    "        print('第{}个分类器 errorRate: {}'.format(i, errorRate))\n",
    "        \n",
    "    return weakClassfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoost(dataMat, weakClassfier):\n",
    "    row, col = dataMat.shape\n",
    "    aggClassEst = np.mat(np.zeros((row, 1)))\n",
    "    for wCf in weakClassfier:\n",
    "        classEst = stumpClassify(dataMat, wCf['dim'], wCf['threshVal'], wCf['threshIneq'])\n",
    "        aggClassEst += wCf['alpha'] * classEst\n",
    "        print('aggClassEst:', aggClassEst)\n",
    "    return np.sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个分类器 aggClassEst : [[ 0.77022252]\n",
      " [ 0.77022252]\n",
      " [ 0.77022252]\n",
      " [ 0.77022252]\n",
      " [ 0.77022252]\n",
      " [ 0.77022252]\n",
      " [-0.77022252]\n",
      " [ 0.77022252]\n",
      " [-0.77022252]\n",
      " [ 0.77022252]\n",
      " [-0.77022252]\n",
      " [-0.77022252]\n",
      " [-0.77022252]\n",
      " [-0.77022252]\n",
      " [ 0.77022252]\n",
      " [-0.77022252]\n",
      " [-0.77022252]]\n",
      "第0个分类器 errorRate: -0.058823529411764705\n",
      "第1个分类器 aggClassEst : [[ 1.69404342]\n",
      " [ 1.69404342]\n",
      " [ 1.69404342]\n",
      " [ 1.69404342]\n",
      " [ 1.69404342]\n",
      " [ 1.69404342]\n",
      " [ 0.15359838]\n",
      " [ 1.69404342]\n",
      " [ 0.15359838]\n",
      " [-0.15359838]\n",
      " [-1.69404342]\n",
      " [-1.69404342]\n",
      " [ 0.15359838]\n",
      " [ 0.15359838]\n",
      " [-0.15359838]\n",
      " [ 0.15359838]\n",
      " [ 0.15359838]]\n",
      "第1个分类器 errorRate: -0.29411764705882354\n",
      "第2个分类器 aggClassEst : [[ 0.83158064]\n",
      " [ 2.5565062 ]\n",
      " [ 0.83158064]\n",
      " [ 0.83158064]\n",
      " [ 0.83158064]\n",
      " [ 0.83158064]\n",
      " [-0.7088644 ]\n",
      " [ 0.83158064]\n",
      " [-0.7088644 ]\n",
      " [-1.01606116]\n",
      " [-2.5565062 ]\n",
      " [-2.5565062 ]\n",
      " [-0.7088644 ]\n",
      " [-0.7088644 ]\n",
      " [-1.01606116]\n",
      " [-0.7088644 ]\n",
      " [-0.7088644 ]]\n",
      "第2个分类器 errorRate: 0.058823529411764705\n",
      "第3个分类器 aggClassEst : [[ 1.62483038]\n",
      " [ 3.34975594]\n",
      " [ 1.62483038]\n",
      " [ 1.62483038]\n",
      " [ 1.62483038]\n",
      " [ 1.62483038]\n",
      " [ 0.08438534]\n",
      " [ 1.62483038]\n",
      " [-1.50211414]\n",
      " [-0.22281142]\n",
      " [-3.34975594]\n",
      " [-3.34975594]\n",
      " [ 0.08438534]\n",
      " [ 0.08438534]\n",
      " [-0.22281142]\n",
      " [-1.50211414]\n",
      " [-1.50211414]]\n",
      "第3个分类器 errorRate: -0.11764705882352941\n",
      "第4个分类器 aggClassEst : [[ 2.19977499]\n",
      " [ 2.77481133]\n",
      " [ 1.04988577]\n",
      " [ 1.04988577]\n",
      " [ 1.04988577]\n",
      " [ 1.04988577]\n",
      " [-0.49055927]\n",
      " [ 1.04988577]\n",
      " [-2.07705875]\n",
      " [-0.79775602]\n",
      " [-3.92470055]\n",
      " [-3.92470055]\n",
      " [-0.49055927]\n",
      " [-0.49055927]\n",
      " [-0.79775602]\n",
      " [-2.07705875]\n",
      " [-2.07705875]]\n",
      "第4个分类器 errorRate: 0.058823529411764705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'alpha': 0.7702225204735745,\n",
       "  'dim': 1,\n",
       "  'ineq': 'lt',\n",
       "  'thresh': 0.20920000000000002},\n",
       " {'alpha': 0.9238208993747057, 'dim': 0, 'ineq': 'lt', 'thresh': 0.4023},\n",
       " {'alpha': 0.8624627800932602, 'dim': 0, 'ineq': 'lt', 'thresh': 0.7209},\n",
       " {'alpha': 0.7932497413463995,\n",
       "  'dim': 1,\n",
       "  'ineq': 'lt',\n",
       "  'thresh': 0.12560000000000002},\n",
       " {'alpha': 0.5749446067975488, 'dim': 1, 'ineq': 'lt', 'thresh': 0.3764}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaBoostTrain(dataMat, labelMat, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
