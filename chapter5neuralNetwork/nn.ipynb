{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "yita = 0.01\n",
    "STEPS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('watermelon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input:\n",
    "    dataframe:df数据集\n",
    "    test_ratio:验证集的比例\n",
    "output:\n",
    "    训练集、测试集\n",
    "\"\"\"\n",
    "def trainTestSplit(dataframe, test_ratio = 0.3):\n",
    "    row, col = dataframe.shape\n",
    "    randomIndex = np.random.permutation(row)\n",
    "#     print(randomIndex)\n",
    "\n",
    "    trainNum = int(row * (1-test_ratio))\n",
    "    trainIndex = randomIndex[:trainNum]\n",
    "    testIndex = randomIndex[trainNum:]\n",
    "    train_data = dataframe.ix[trainIndex]\n",
    "    test_data = dataframe.ix[testIndex]\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = trainTestSplit(df,test_ratio = 0.2)\n",
    "# print(train_data)\n",
    "# print(test_data)\n",
    "train_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_x = train_data[['density','ratio_suger']].values\n",
    "# ind = train_data.index[train_data['label']==0]\n",
    "# print(ind)\n",
    "# train_data.loc[ind,'label'] = -1\n",
    "print(train_data)\n",
    "data_y = train_data['label'].values \n",
    "data_y = to_categorical(data_y)\n",
    "test_x = test_data[['density','ratio_suger']].values\n",
    "test_y = test_data['label'].values\n",
    "test_y = to_categorical(test_y)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes=None):\n",
    "    y = np.array(y, dtype='int')\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes))\n",
    "    categorical[np.arange(n), y] = 1\n",
    "#     print(categorical)\n",
    "#     output_shape = input_shape + (num_classes,)\n",
    "# #     print(input_shape)\n",
    "# #     print(output_shape)\n",
    "#     categorical = np.reshape(categorical, output_shape)\n",
    "    \n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_y.shape)\n",
    "#print((4,9)+(2,3))\n",
    "# arr = np.zeros((3,3))\n",
    "# arr[[0,1],0] = 1\n",
    "# print(arr)\n",
    "to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(w1, b1, w2, b2, x):\n",
    "    fctemp = np.dot(x,w1) + b1\n",
    "    fc1 = 1 / (1 + np.exp(-fctemp))\n",
    "    fctemp = np.dot(fc1, w2) + b2\n",
    "    fc2 = 1 / (1 + np.exp(-fctemp))\n",
    "    \n",
    "    return fc1,fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "a[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "构建神经网络\n",
    "\"\"\"\n",
    "w1 = np.random.rand(2,2)\n",
    "b1 = np.random.rand(2)\n",
    "w2 = np.random.rand(2,2)\n",
    "b2 = np.random.rand(2)\n",
    "\n",
    "row, col = data_x.shape\n",
    "\n",
    "for step in range(STEPS):\n",
    "    E = 0\n",
    "    for i in range(row):\n",
    "        x = data_x[i]\n",
    "        y = data_y[i]\n",
    "        fc1, y_ = inference(w1, b1, w2, b2, x)\n",
    "#         print('fc1:',fc1, 'type:fc1:', type(fc1), 'y_', y_)\n",
    "#         print('y:', y, 'y_:', y_)\n",
    "        Ek = np.sum(np.power((y - y_), 2)) / 2\n",
    "    #     print(i, y_)\n",
    "    #     print(i,Ek)\n",
    "        E += Ek\n",
    "        g = y_ * (1 - y_) * (y - y_)\n",
    "        e = fc1 * (1 - fc1) * np.dot(w2 , g)\n",
    "#         print(i, e)\n",
    "        w1 += yita * np.mat(x).T * np.mat(e)\n",
    "        b1 += -yita * e\n",
    "        w2 += yita * np.mat(fc1).T * np.mat(g)\n",
    "        b2 += -yita * g\n",
    "    if step % 10 == 0:\n",
    "#         _, y_ = inference(w1, b1, w2, b2, )\n",
    "        \n",
    "        print('After {} training steps, E is {}.'.format(step, E))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "构建神经网络\n",
    "\"\"\"\n",
    "w1 = np.random.rand(2,2)\n",
    "b1 = np.random.rand(2)\n",
    "w2 = np.random.rand(2,2)\n",
    "b2 = np.random.rand(2)\n",
    "\n",
    "row, col = data_x.shape\n",
    "\n",
    "for step in range(STEPS):\n",
    "    E = 0\n",
    "    for i in range(row):\n",
    "        x = data_x[i]\n",
    "        y = data_y[i]\n",
    "        fc1, y_ = inference(w1, b1, w2, b2, x)\n",
    "#         print('fc1:',fc1, 'type:fc1:', type(fc1), 'y_', y_)\n",
    "        print('y:', y, 'y_:', y_)\n",
    "        Ek = np.sum(np.power((y - y_), 2)) / 2\n",
    "    #     print(i, y_)\n",
    "    #     print(i,Ek)\n",
    "        E += Ek\n",
    "        g = []\n",
    "        for j in range(len(y_)):\n",
    "            gj = y_[j] * (1 - y_[j]) * (y[j] - y_[j])\n",
    "            b2[j] += -yita * gj\n",
    "            g.append(gj)\n",
    "        e = []\n",
    "        for h in range(len(fc1)):\n",
    "            eh = fc1[h] * (1 - fc1[h]) * np.dot(w2[h] , np.array(g))\n",
    "            b1[h] += -yita * eh \n",
    "            e.append(eh)\n",
    "        \n",
    "        print(i, e)\n",
    "        for i in range(len(x)):\n",
    "            for h in range(len(fc1)):\n",
    "                w1[i][h] += yita * e[h] * x[i]\n",
    "        for h in range(len(fc1)):\n",
    "            for j in range(len(y_)):\n",
    "                w2[h][j] += yita * g[j] * fc1[h] \n",
    "    if step % 10 == 0:\n",
    "#         _, y_ = inference(w1, b1, w2, b2, )\n",
    "        \n",
    "        print('After {} training steps, E is {}.'.format(step, E))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = df[['根蒂','脐部']]\n",
    "ind = traindf.index[traindf['脐部'] == '凹陷']\n",
    "traindf.loc[ind,'脐部'] = 0\n",
    "ind = traindf.index[traindf['脐部'] == '稍凹']\n",
    "traindf.loc[ind,'脐部'] = 1\n",
    "ind = traindf.index[traindf['脐部'] == '平坦']\n",
    "traindf.loc[ind,'脐部'] = 2\n",
    "ind = traindf.index[traindf['根蒂'] == '蜷缩']\n",
    "traindf.loc[ind,'根蒂'] = 0\n",
    "ind = traindf.index[traindf['根蒂'] == '稍蜷']\n",
    "traindf.loc[ind,'根蒂'] = 1\n",
    "ind = traindf.index[traindf['根蒂'] == '硬挺']\n",
    "traindf.loc[ind,'根蒂'] = 2\n",
    "data_x = traindf.values\n",
    "data_y = df['label'].values\n",
    "data_y = to_categorical(data_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
